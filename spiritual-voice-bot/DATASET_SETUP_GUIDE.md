# Bhagavad Gita Dataset Setup Guide

## ğŸ“Š Dataset Information

**Source**: [Kaggle - Bhagavad Gita Dataset](https://www.kaggle.com/datasets/a2m2a2n2/bhagwad-gita-dataset)

**What you'll get**: Complete Bhagavad Gita with all 700 verses including:
- Sanskrit original text
- English translations
- Transliterations
- Commentary/meanings
- Chapter and verse numbers

---

## ğŸš€ Quick Setup (3 Steps)

### Step 1: Download the Dataset

#### Option A: Manual Download (Easiest)
1. Visit: https://www.kaggle.com/datasets/a2m2a2n2/bhagwad-gita-dataset
2. Click **"Download"** button (requires free Kaggle account)
3. Extract the ZIP file
4. You'll get CSV/JSON files with verses

#### Option B: Kaggle API (If you prefer automation)
```bash
# Install Kaggle CLI
pip install kaggle

# Setup API credentials (first time only)
# 1. Go to https://www.kaggle.com/settings
# 2. Click "Create New API Token"
# 3. Save kaggle.json to ~/.kaggle/
# 4. Run: chmod 600 ~/.kaggle/kaggle.json

# Download dataset
kaggle datasets download -d a2m2a2n2/bhagwad-gita-dataset
unzip bhagwad-gita-dataset.zip
```

### Step 2: Place the Dataset Files

Copy the downloaded CSV/JSON files to:
```
backend/data/raw/
```

Create the directory if it doesn't exist:
```bash
cd backend
mkdir -p data/raw
# Copy your dataset files here
```

### Step 3: Run Ingestion Script

```bash
cd backend
python3 scripts/ingest_bhagavad_gita.py
```

This will:
1. Parse all verses from the dataset
2. Generate embeddings using Sentence Transformers
3. Save processed data to `data/processed/`

---

## ğŸ“ Expected File Structure

After setup, your backend should look like:

```
backend/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                           # Downloaded dataset
â”‚   â”‚   â””â”€â”€ bhagavad_gita.csv         # (or .json)
â”‚   â””â”€â”€ processed/                     # Generated by ingestion
â”‚       â”œâ”€â”€ bhagavad_gita_processed.json   # With embeddings
â”‚       â””â”€â”€ bhagavad_gita_verses.json      # Verses only
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_bhagavad_gita.py     # Download instructions
â”‚   â””â”€â”€ ingest_bhagavad_gita.py       # Data ingestion script
â””â”€â”€ rag/
    â””â”€â”€ pipeline.py                    # Auto-loads processed data
```

---

## ğŸ”§ Ingestion Script Features

The `ingest_bhagavad_gita.py` script:

### Automatic Dataset Detection
- Finds CSV and JSON files in `data/raw/`
- Flexibly handles different field names
- Works with various dataset formats

### Field Mapping (Flexible)
Automatically detects columns like:
- **Chapter**: chapter, chapter_num, chapter_number, adhyaya
- **Verse**: verse, verse_num, verse_number, shloka
- **Text**: text, verse_text, translation, english
- **Sanskrit**: sanskrit, sanskrit_text, original
- **Meaning**: meaning, explanation, commentary

### Processing Steps
1. **Parse**: Reads CSV/JSON files
2. **Clean**: Removes duplicates, validates data
3. **Topic Inference**: Auto-categorizes verses by topic
4. **Embeddings**: Generates 768-dim vectors
5. **Save**: Outputs JSON with metadata

### Output Format
```json
{
  "verses": [
    {
      "chapter": 2,
      "verse": 47,
      "text": "You have a right to perform...",
      "sanskrit": "à¤•à¤°à¥à¤®à¤£à¥à¤¯à¥‡à¤µà¤¾à¤§à¤¿à¤•à¤¾à¤°à¤¸à¥à¤¤à¥‡...",
      "meaning": "This verse teaches...",
      "reference": "Bhagavad Gita 2.47",
      "scripture": "Bhagavad Gita",
      "topic": "Karma Yoga",
      "language": "en",
      "embedding": [0.123, -0.456, ...]  // 768-dim vector
    }
  ],
  "metadata": {
    "total_verses": 700,
    "embedding_dim": 768,
    "embedding_model": "paraphrase-multilingual-mpnet-base-v2"
  }
}
```

---

## ğŸ¯ How It Integrates with Your Bot

### Automatic Loading
The RAG pipeline (`backend/rag/pipeline.py`) automatically:
1. Checks for processed dataset on startup
2. Loads all verses and embeddings
3. Falls back to 8 sample verses if dataset not found

### Startup Logs
**With dataset:**
```
INFO: Loading processed dataset from data/processed/bhagavad_gita_processed.json
INFO: âœ… Loaded 700 verses from Bhagavad Gita dataset
INFO: Embedding dimension: 768
```

**Without dataset (fallback):**
```
WARNING: âš ï¸  Using sample data (8 verses only)
WARNING: Run: python3 scripts/ingest_bhagavad_gita.py to load full dataset
INFO: Loaded 8 sample scripture passages
```

### Query Performance
- **With 8 verses**: Limited answers, may not find relevant verse
- **With 700 verses**: Comprehensive coverage, better matches

---

## ğŸ§ª Testing After Setup

### 1. Check Data Directory
```bash
ls -lh backend/data/raw/          # Should see dataset file(s)
ls -lh backend/data/processed/    # Should see processed JSON files
```

### 2. Verify Processed Data
```bash
# Check verse count
cat backend/data/processed/bhagavad_gita_verses.json | grep -c "chapter"

# View a sample verse
cat backend/data/processed/bhagavad_gita_verses.json | head -n 50
```

### 3. Start Backend and Check Logs
```bash
cd backend
python -m uvicorn main:app --reload

# Look for:
# âœ… Loaded 700 verses from Bhagavad Gita dataset
```

### 4. Test Query
```bash
curl -X POST "http://localhost:8000/api/text/query" \
  -H "Content-Type: application/json" \
  -d '{"query": "What does Krishna say about meditation?", "language": "en"}'
```

Should now return verses specifically about meditation!

---

## ğŸ“Š Dataset Comparison

### Before (Sample Data)
- **Verses**: 8
- **Coverage**: Very limited
- **Topics**: Basic concepts only
- **Search Quality**: May miss relevant verses

### After (Full Dataset)
- **Verses**: 700 (complete Bhagavad Gita)
- **Coverage**: Comprehensive
- **Topics**: All 18 chapters covered
- **Search Quality**: High-quality semantic matches

---

## ğŸ”§ Troubleshooting

### "No dataset files found"
**Problem**: Script can't find dataset in `data/raw/`

**Solution**:
```bash
# Check directory exists
ls backend/data/raw/

# If empty, download dataset and copy files there
# See Step 1 above
```

### "No verses extracted"
**Problem**: Dataset format not recognized

**Solution**:
```bash
# Check your dataset file
head -n 5 backend/data/raw/your_file.csv

# The ingestion script is flexible, but if it still fails:
# Open an issue with your dataset structure
```

### "sentence-transformers not available"
**Problem**: Missing dependency

**Solution**:
```bash
cd backend
pip install sentence-transformers
```

### "Out of memory during embedding generation"
**Problem**: Too many verses for available RAM

**Solution**:
```python
# Edit ingest_bhagavad_gita.py
# Line ~XXX: Change batch size
self.embedding_model.encode(texts, batch_size=16)  # Lower if needed
```

### "Embeddings not loading"
**Problem**: Processed file corrupted

**Solution**:
```bash
# Delete and regenerate
rm backend/data/processed/bhagavad_gita_processed.json
python3 scripts/ingest_bhagavad_gita.py
```

---

## ğŸš€ Advanced: Custom Dataset Structure

If your dataset has different field names, edit the ingestion script:

```python
# In ingest_bhagavad_gita.py, line ~60
field_mappings = {
    'chapter': ['chapter', 'your_chapter_field_name'],
    'verse': ['verse', 'your_verse_field_name'],
    'text': ['text', 'your_translation_field_name'],
    # Add your custom field names here
}
```

---

## ğŸ“ˆ Performance Impact

### Ingestion Time
- **Parsing**: ~5-10 seconds
- **Embedding generation**: ~2-5 minutes (CPU)
- **Total**: ~5-10 minutes for full dataset

### Runtime Performance
- **Loading**: ~1-2 seconds on startup
- **Query search**: ~50-100ms (same as before)
- **Memory usage**: ~500MB for 700 verses with embeddings

---

## ğŸ¯ Next Steps After Setup

1. **Test Queries**: Ask diverse questions to test coverage
2. **Expand Topics**: Add more topic keywords for better categorization
3. **Add Translations**: Include Hindi translations if in dataset
4. **Optimize Search**: Tune similarity thresholds for better results

---

## ğŸ“ Summary

**What we built:**
âœ… Flexible dataset ingestion pipeline
âœ… Automatic field mapping
âœ… Embedding generation
âœ… Seamless integration with RAG pipeline
âœ… Fallback to sample data if needed

**To get started:**
1. Download dataset from Kaggle
2. Copy to `backend/data/raw/`
3. Run: `python3 scripts/ingest_bhagavad_gita.py`
4. Restart backend - now with 700 verses!

---

## ğŸ†˜ Need Help?

- **Dataset issues**: Check Kaggle dataset page for format
- **Ingestion errors**: Run with verbose logging
- **Integration issues**: Check backend startup logs
- **Questions**: Open an issue on GitHub

Your spiritual bot now has access to the complete Bhagavad Gita! ğŸ•‰ï¸
